{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide clear instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps human by generating tutorials given a text.\n",
    "You will be provided with a text. If the text contains any kind of istructions on how to proceed with something, generate a tutorial in a bullet list.\n",
    "Otherwise, inform the user that the text does not contain any instructions.\n",
    "\n",
    "Text: \n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "To prepare the known sauce from Genova, Italy, you can start by toasting the pine nuts to then coarsely \n",
    "chop them in a kitchen mortar together with basil and garlic. Then, add half of the oil in the kitchen mortar and season with salt and pepper.\n",
    "Finally, transfer the pesto to a bowl and stir in the grated Parmesan cheese.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- How to Prepare Genovese Sauce:\n",
      "    1. Start by toasting the pine nuts.\n",
      "    2. Coarsely chop the toasted pine nuts in a kitchen mortar with basil and garlic.\n",
      "    3. Add half of the oil in the kitchen mortar and season with salt and pepper.\n",
      "    4. Transfer the pesto to a bowl.\n",
      "    5. Stir in the grated Parmesan cheese.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()  # Assumes OPENAI_API_KEY is set in environment variables\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": instructions},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but the text provided does not contain any instructions. If you need help with something specific, please let me know!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": 'the sun is shining and dogs are running on the beach.'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split complex tasks into subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that summarize articles. \n",
    "To complete this task, do the following subtasks:\n",
    "\n",
    "Read the provided article context comprehensively and identified the main topic and key points\n",
    "Generated a paragraph summary of the current article context that captures the essential information and conveys the main idea\n",
    "Print each step of the proces.\n",
    "Article:\n",
    "\"\"\"\n",
    "\n",
    "article = \"\"\"\n",
    "Recurrent neural networks, long short-term memory and gated recurrent neural networks\n",
    "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
    "transduction problems such as language modeling and machine translation. Numerous\n",
    "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
    "architectures.\n",
    "Recurrent models typically factor computation along the symbol positions of the input and output\n",
    "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
    "states ht, as a function of the previous hidden state ht-1 and the input for position t. This inherently\n",
    "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
    "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
    "significant improvements in computational efficiency through factorization tricks and conditional\n",
    "computation, while also improving model performance in case of the latter. The fundamental\n",
    "constraint of sequential computation, however, remains.\n",
    "Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
    "the input or output sequences. In all but a few cases, however, such attention mechanisms\n",
    "are used in conjunction with a recurrent network.\n",
    "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
    "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
    "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
    "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B0ww1zPBXbfPzWqHpJAMH7Xr0ffDr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Step 1: Identify the main topic and key points\\nMain Topic: The article discusses the use of recurrent neural networks, particularly long short-term memory and gated recurrent neural networks, in sequence modeling and transduction problems like language modeling and machine translation.\\nKey Points:\\n1. Recurrent neural networks, especially LSTM and GRNNs, are state-of-the-art in sequence modeling.\\n2. Efforts have been ongoing to advance recurrent language models and encoder-decoder architectures.\\n3. Recurrent models compute along symbol positions of input and output sequences sequentially, posing limitations on parallelization.\\n4. Attention mechanisms are now commonly used in conjunction with recurrent networks for sequence modeling.\\n5. The article introduces the Transformer model architecture, which relies on attention mechanisms instead of recurrence, allowing for increased parallelization and improved translation quality.\\n\\nStep 2: Generate a paragraph summary\\nThe article discusses the dominance of recurrent neural networks like LSTM and GRNNs in sequence modeling tasks such as language modeling and machine translation. These models compute sequentially, hindering parallelization, but recent advancements have improved computational efficiency. Attention mechanisms have become crucial in modeling dependencies, often in combination with recurrent networks. Introducing the Transformer model, the article proposes a non-recurrent architecture relying solely on attention mechanisms. This innovation enables enhanced parallelization, leading to a new benchmark in translation quality with minimal training time.\\n\\nStep 3: Print each step of the process\\n- Step 1: Main Topic and Key Points Identified\\n- Step 2: Paragraph Summary Generated', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1739566245, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=304, prompt_tokens=405, total_tokens=709, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Step 1: Identify the main topic and key points\n",
      "Main Topic: The article discusses the use of recurrent neural networks, particularly long short-term memory and gated recurrent neural networks, in sequence modeling and transduction problems like language modeling and machine translation.\n",
      "Key Points:\n",
      "1. Recurrent neural networks, especially LSTM and GRNNs, are state-of-the-art in sequence modeling.\n",
      "2. Efforts have been ongoing to advance recurrent language models and encoder-decoder architectures.\n",
      "3. Recurrent models compute along symbol positions of input and output sequences sequentially, posing limitations on parallelization.\n",
      "4. Attention mechanisms are now commonly used in conjunction with recurrent networks for sequence modeling.\n",
      "5. The article introduces the Transformer model architecture, which relies on attention mechanisms instead of recurrence, allowing for increased parallelization and improved translation quality.\n",
      "\n",
      "Step 2: Generate a paragraph summary\n",
      "The article discusses the dominance of recurrent neural networks like LSTM and GRNNs in sequence modeling tasks such as language modeling and machine translation. These models compute sequentially, hindering parallelization, but recent advancements have improved computational efficiency. Attention mechanisms have become crucial in modeling dependencies, often in combination with recurrent networks. Introducing the Transformer model, the article proposes a non-recurrent architecture relying solely on attention mechanisms. This innovation enables enhanced parallelization, leading to a new benchmark in translation quality with minimal training time.\n",
      "\n",
      "Step 3: Print each step of the process\n",
      "- Step 1: Main Topic and Key Points Identified\n",
      "- Step 2: Paragraph Summary Generated\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": article},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in generating essays shorter than 500 words.\n",
    "Given a statement, develop the essay the best you can.\n",
    "Once the essay is generated, provide clear justifications and explanations of the reasons behind the sentences you generated.\n",
    "\n",
    "Statement:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "statement = \"\"\"\n",
    "An introduction to mammals like chickens.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mammals, a diverse group of animals characterized by their hair or fur, mammary glands, and warm-blooded nature, encompass a wide range of species including familiar ones like dogs, cats, and elephants. However, when discussing mammals, it's important to clarify that chickens, while often mistakenly categorized as mammals due to their superficial similarities like warm-bloodedness and giving birth to live young, are actually avian creatures belonging to the bird class. Though chickens share some traits with mammals like regulating body temperature internally and displaying maternal behaviors, their physiological and evolutionary differences firmly place them in the avian category, distinct from true mammals. Through this clarification, we can appreciate the fascinating diversity within the animal kingdom and the unique characteristics that define each group.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": statement},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, solve it the best you can.\n",
    "Provide a clear justification of your answer and the reasoning behind it.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to this riddle is a clock. \n",
      "\n",
      "Explanation:\n",
      "- A clock has a face with numbers and hands (hour and minute hands) to indicate the time.\n",
      "- A clock does not have arms or legs like a living being would, but it does have hands (the clock hands) that move to tell the time.\n",
      "- Therefore, a clock fits the description of having a face and two hands, but no arms or legs.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": riddle},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate many output - self consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, you have to generate three answers to the riddle.\n",
    "For each answer, be specific about the reasoning you made.\n",
    "Then, among the three answer, select the one which is most plausible given the riddle.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "There are four friends: Alice, Bob, Charlie, and David. They each have a different favorite color: red, blue, green, and yellow. They also each have a different favorite animal: cat, dog, fish, and bird. Using the following clues, can you figure out who likes what color and what animal?\n",
    "\n",
    "Alice does not like red or blue.\n",
    "Bob likes dogs, but not green.\n",
    "Charlie likes fish, but not yellow.\n",
    "David likes yellow, but not cats.\n",
    "The person who likes red also likes birds.\n",
    "The person who likes blue also likes cats.\n",
    "\n",
    "You can write your answer in the form of four sentences, such as “Alice likes green and fish.” \n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, you have to generate three answers to the riddle.\n",
    "For each answer, be specific about the reasoning you made.\n",
    "Then, among the three answer, select the one which is most plausible given the riddle.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: A clock\n",
      "Reasoning: A clock has a face with numbers and two hands for telling time, but it does not have arms or legs.\n",
      "\n",
      "Answer 2: A wall clock\n",
      "Reasoning: Similar to a regular clock, a wall clock also has a face and two hands but no arms or legs.\n",
      "\n",
      "Answer 3: A watch\n",
      "Reasoning: A watch is worn on the wrist and has a face with numbers, as well as two hands to tell time, but it does not have arms or legs.\n",
      "\n",
      "Among the three answers, the most plausible one is \"A clock\" as it is a common object that fits the description of having a face and two hands without having arms or legs.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": riddle},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conversation = \"\"\"\n",
    "Customer: Hi, I need some help with my order.\n",
    "AI agent: Hello, welcome to our online store. I'm an AI agent and I'm here to assist you. \n",
    "Customer: I ordered a pair of shoes yesterday, but I haven't received a confirmation email yet. Can you check the status of my order?\n",
    "AI agent: Sure, I can help you with that. Can you please provide me with your order number and email address?\n",
    "Customer: Yes, my order number is 123456789 and my email is john.doe@example.com.\n",
    "AI agent: Thank you. I have found your order in our system. It looks like your order is still being processed and it will be shipped soon. You should receive a confirmation email within 24 hours.\n",
    "Customer: OK, thank you for the information. How long will it take for the shoes to arrive?\n",
    "AI agent: You're welcome. According to our shipping policy, it will take about 3 to 5 business days for the shoes to arrive at your address. You can track your order online using the tracking number that will be sent to your email once your order is shipped.\n",
    "Customer: Alright, sounds good. Thank you for your help.\n",
    "AI agent: It's my pleasure. Is there anything else I can do for you today?\n",
    "Customer: No, that's all. Have a nice day.\n",
    "AI agent: Thank you for choosing our online store. Have a nice day too. Goodbye. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": conversation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "{conversation}\n",
    "\n",
    "Remember to return only the sentiment, in lower cap and without punctuation!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A neutron is a subatomic particle that has a neutral (not positive or negative) charge, and a mass slightly greater than that of a proton. \n",
    "It is present in all atomic nuclei except those of ordinary hydrogen. \n",
    "Neutrons, along with protons and electrons, are one of the three basic particles making up atoms. \n",
    "The term “neutron” comes from the fact that it is electrically neutral, meaning it carries no charge.\n",
    "\"\"\"\n",
    "\n",
    "system_message = f\"\"\"\n",
    "Reframe the text for a 5 years old child. It should be shorter than 500 words. Make a parallelism with animals.\n",
    "\n",
    "The text is the following:\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine neutrons as special animals that live in a house called an atomic nucleus. They are like a big sibling to protons and electrons, together they make up an atom family. Neutrons are unique because they have no charge, unlike their positive and negative siblings. They are a bit heavier than protons but still work together to keep the atomic family strong. So just like how different animals work together in a big zoo, neutrons, protons, and electrons work together in atoms to create everything around us.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a Python expert that produces python code as per user's request.\n",
    "\n",
    "===>START EXAMPLE\n",
    "\n",
    "---User Query---\n",
    "Give me a function to print a string of text.\n",
    "\n",
    "---User Output---\n",
    "Below you can find the described function:\n",
    "```def my_print(text):\n",
    "     return print(text)\n",
    "```\n",
    "<===END EXAMPLE\n",
    "\"\"\"\n",
    "\n",
    "query = \"generate a python function to calculate the nth Fibonacci number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below you can find the described function:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return \"Invalid input. Please provide a positive integer for n.\"\n",
      "    elif n == 1:\n",
      "        return 0\n",
      "    elif n == 2:\n",
      "        return 1\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "```\n",
      "\n",
      "This function calculates the nth Fibonacci number efficiently using iteration. Just call `fibonacci(n)` with the desired value of `n` to get the nth Fibonacci number.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
    "Given a product name, produce a tagline similar to the following examples:\n",
    "\n",
    "Peak Pursuit - Conquer Heights with Comfort\n",
    "Summit Steps - Your Partner for Every Ascent\n",
    "Crag Conquerors - Step Up, Stand Tal\n",
    "\n",
    "Product name:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "product_name = 'Elevation Embrace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation Embrace - Embrace the Highs in Style\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": product_name},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movie.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.5/libexec/lib/python3.13/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movie.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd .read_csv('movie.csv', encoding='utf-8')\n",
    "df['label'] = df['label'].replace({0: 'Negative', 1: 'Positive'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=10, random_state=42)  # Change the value of 'random_state' as needed for reproducibility\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a binary classifier for sentiment analysis.\n",
    "Given a text, based on its sentiment you classify it into one of two categories: positive or negative.\n",
    "\n",
    "You can use the following texts as examples:\n",
    "\n",
    "Text: \"I love this product! It's fantastic and works perfectly.\"\n",
    "Positive\n",
    "\n",
    "Text: \"I'm really disappointed with the quality of the food.\"\n",
    "Negative\n",
    "\n",
    "Text: \"This is the best day of my life!\"\n",
    "Positive\n",
    "\n",
    "Text: \"I can't stand the noise in this restaurant.\"\n",
    "Negative\n",
    "\n",
    "ONLY return the sentiment as output (without punctuation).\n",
    "\n",
    "Text:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text = \"The concert was amazing! The band was incredible!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      3\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         ]\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(process_text)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "df['predicted'] = df['text'].apply(process_text)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>The central theme in this movie seems to be co...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16298</th>\n",
       "      <td>An excellent example of \"cowboy noir\", as it's...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28505</th>\n",
       "      <td>The ending made my heart jump up into my throa...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>Only the chosen ones will appreciate the quali...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26893</th>\n",
       "      <td>This is a really funny film, especially the se...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  predicted\n",
       "32823  The central theme in this movie seems to be co...  Negative   Negative\n",
       "16298  An excellent example of \"cowboy noir\", as it's...  Positive  Positive.\n",
       "28505  The ending made my heart jump up into my throa...  Negative   Positive\n",
       "6689   Only the chosen ones will appreciate the quali...  Positive   Positive\n",
       "26893  This is a really funny film, especially the se...  Positive   Positive"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "To solve a generic first-degree equation, follow these steps:\n",
    "\n",
    "1. **Identify the Equation:** Start by identifying the equation you want to solve. It should be in the form of \"ax + b = c,\" where 'a' is the coefficient of the variable, 'x' is the variable, 'b' is a constant, and 'c' is another constant.\n",
    "\n",
    "2. **Isolate the Variable:** Your goal is to isolate the variable 'x' on one side of the equation. To do this, perform the following steps:\n",
    "   \n",
    "   a. **Add or Subtract Constants:** Add or subtract 'b' from both sides of the equation to move constants to one side.\n",
    "   \n",
    "   b. **Divide by the Coefficient:** Divide both sides by 'a' to isolate 'x'. If 'a' is zero, the equation may not have a unique solution.\n",
    "\n",
    "3. **Simplify:** Simplify both sides of the equation as much as possible.\n",
    "\n",
    "4. **Solve for 'x':** Once 'x' is isolated on one side, you have the solution. It will be in the form of 'x = value.'\n",
    "\n",
    "5. **Check Your Solution:** Plug the found value of 'x' back into the original equation to ensure it satisfies the equation. If it does, you've found the correct solution.\n",
    "\n",
    "6. **Express the Solution:** Write down the solution in a clear and concise form.\n",
    "\n",
    "7. **Consider Special Cases:** Be aware of special cases where there may be no solution or infinitely many solutions, especially if 'a' equals zero.\n",
    "\n",
    "\n",
    "Equation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "equation = \"3x + 5 = 11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. Identify the Equation:**\n",
      "The given equation is 3x + 5 = 11.\n",
      "\n",
      "**2. Isolate the Variable:**\n",
      "   a. Subtract 5 from both sides:\n",
      "      3x + 5 - 5 = 11 - 5\n",
      "      3x = 6\n",
      "      \n",
      "   b. Divide by 3 on both sides:\n",
      "      3x / 3 = 6 / 3\n",
      "      x = 2\n",
      "\n",
      "**3. Simplify:**\n",
      "The equation simplifies to x = 2.\n",
      "\n",
      "**4. Solve for x:**\n",
      "The solution to the equation is x = 2.\n",
      "\n",
      "**5. Check Your Solution:**\n",
      "Plug x = 2 back into the original equation:\n",
      "3(2) + 5 = 11\n",
      "6 + 5 = 11\n",
      "11 = 11\n",
      "The solution x = 2 satisfies the equation.\n",
      "\n",
      "**6. Express the Solution:**\n",
      "The solution to the equation 3x + 5 = 11 is x = 2.\n",
      "\n",
      "**7. Consider Special Cases:**\n",
      "Since the coefficient of x is not zero, this equation has a unique solution, and that is x = 2.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": equation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openaivaalt.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"8d236d7c6ed945ddb80358800bd2866c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "# Import Azure OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    deployment_name='gpt-3.5-turbo',\n",
    "    openai_api_type=\"azure\",\n",
    ")\n",
    "\n",
    "model(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French. I love programming.\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "    ]\n",
    "\n",
    "agent_executor = initialize_agent(tools, model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should search for recent news or updates about the Italian male athletes for climbing at the Paris 2024 Olympics\n",
      "Action: Search\n",
      "Action Input: \"Italian male athletes climbing Paris 2024 Olympics\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mA select group of climbers ensured their participation in the 2024 Paris Olympics. Among them, Italy's Matteo Zurloni and Indonesia's Desak Made Rita Kusuma Dewi didn't just secure their Olympic berths; they also took home the world titles in their respective categories.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to refine my search to find a more comprehensive list of Italian male climbers for Paris 2024 Olympics\n",
      "Action: Search\n",
      "Action Input: \"List of Italian male climbers Paris 2024 Olympics\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mItaly fielded a squad of five male gymnasts for Paris after advancing to the final round ... Paris 2024 qualification berths, and medals table - complete list\".\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThis information does not seem to be readily available, I should try contacting the Italian climbing federation for more information\n",
      "Action: Search\n",
      "Action Input: \"contact information for Italian climbing federation\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIFSC HEADQUARTERS: Corso Vinzaglio 12 10121, Torino, ITALY. Opening Hours: Monday - Friday 9:00 AM - 5:00 PM CEST. IFSC OFFICE:.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can reach out to the Italian climbing federation to ask for a list of their male athletes participating in the Paris 2024 Olympics\n",
      "Action: Contact\n",
      "Action Input: Email or phone call to the Italian climbing federation requesting information on the male athletes for Paris 2024 Olympics\u001b[0m\n",
      "Observation: Contact is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will refine my search further to see if any new information has been released about the Italian male climbers for the Paris 2024 Olympics\n",
      "Action: Search\n",
      "Action Input: \"Latest updates on Italian male climbers for Paris 2024 Olympics\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAleksandra Miroslaw and Bassa Mawem have secured quota spots to next summer's Paris 2024 Olympic Games following respective wins at the IFSC ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information I have gathered, it seems that there is no comprehensive list of Italian male climbers for the Paris 2024 Olympics readily available. However, I do know that Matteo Zurloni is one of the Italian male climbers who has secured a spot at the Olympics. \n",
      "Final Answer: Matteo Zurloni is one of the Italian male climbers who has secured a spot at the Paris 2024 Olympics, but a comprehensive list of Italian male climbers for the Olympics is not readily available.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'who are going to be the italian male athletes for climbing at the Paris 2024 Olympics?',\n",
       " 'output': 'Matteo Zurloni is one of the Italian male climbers who has secured a spot at the Paris 2024 Olympics, but a comprehensive list of Italian male climbers for the Olympics is not readily available.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor('who are going to be the italian male athletes for climbing at the Paris 2024 Olympics?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
