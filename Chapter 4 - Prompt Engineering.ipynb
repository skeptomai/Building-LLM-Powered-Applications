{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide clear instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps human by generating tutorials given a text.\n",
    "You will be provided with a text. If the text contains any kind of istructions on how to proceed with something, generate a tutorial in a bullet list.\n",
    "Otherwise, inform the user that the text does not contain any instructions.\n",
    "\n",
    "Text: \n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "To prepare the known sauce from Genova, Italy, you can start by toasting the pine nuts to then coarsely \n",
    "chop them in a kitchen mortar together with basil and garlic. Then, add half of the oil in the kitchen mortar and season with salt and pepper.\n",
    "Finally, transfer the pesto to a bowl and stir in the grated Parmesan cheese.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()  # Assumes OPENAI_API_KEY is set in environment variables\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": instructions},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": 'the sun is shining and dogs are running on the beach.'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split complex tasks into subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that summarize articles. \n",
    "To complete this task, do the following subtasks:\n",
    "\n",
    "Read the provided article context comprehensively and identified the main topic and key points\n",
    "Generated a paragraph summary of the current article context that captures the essential information and conveys the main idea\n",
    "Print each step of the process.\n",
    "Article:\n",
    "\"\"\"\n",
    "\n",
    "article = \"\"\"\n",
    "Recurrent neural networks, long short-term memory and gated recurrent neural networks\n",
    "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
    "transduction problems such as language modeling and machine translation. Numerous\n",
    "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
    "architectures.\n",
    "Recurrent models typically factor computation along the symbol positions of the input and output\n",
    "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
    "states ht, as a function of the previous hidden state ht-1 and the input for position t. This inherently\n",
    "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
    "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
    "significant improvements in computational efficiency through factorization tricks and conditional\n",
    "computation, while also improving model performance in case of the latter. The fundamental\n",
    "constraint of sequential computation, however, remains.\n",
    "Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
    "the input or output sequences. In all but a few cases, however, such attention mechanisms\n",
    "are used in conjunction with a recurrent network.\n",
    "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
    "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
    "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
    "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": article},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in generating essays shorter than 500 words.\n",
    "Given a statement, develop the essay the best you can.\n",
    "Once the essay is generated, provide clear justifications and explanations of the reasons behind the sentences you generated.\n",
    "\n",
    "Statement:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "statement = \"\"\"\n",
    "An introduction to mammals like chickens.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": statement},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, solve it the best you can.\n",
    "Provide a clear justification of your answer and the reasoning behind it.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": riddle},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate many output - self consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, you have to generate three answers to the riddle.\n",
    "For each answer, be specific about the reasoning you made.\n",
    "Then, among the three answer, select the one which is most plausible given the riddle.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "There are four friends: Alice, Bob, Charlie, and David. They each have a different favorite color: red, blue, green, and yellow. They also each have a different favorite animal: cat, dog, fish, and bird. Using the following clues, can you figure out who likes what color and what animal?\n",
    "\n",
    "Alice does not like red or blue.\n",
    "Bob likes dogs, but not green.\n",
    "Charlie likes fish, but not yellow.\n",
    "David likes yellow, but not cats.\n",
    "The person who likes red also likes birds.\n",
    "The person who likes blue also likes cats.\n",
    "\n",
    "You can write your answer in the form of four sentences, such as “Alice likes green and fish.” \n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Given a riddle, you have to generate three answers to the riddle.\n",
    "For each answer, be specific about the reasoning you made.\n",
    "Then, among the three answer, select the one which is most plausible given the riddle.\n",
    "\n",
    "Riddle:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": riddle},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conversation = \"\"\"\n",
    "Customer: Hi, I need some help with my order.\n",
    "AI agent: Hello, welcome to our online store. I'm an AI agent and I'm here to assist you. \n",
    "Customer: I ordered a pair of shoes yesterday, but I haven't received a confirmation email yet. Can you check the status of my order?\n",
    "AI agent: Sure, I can help you with that. Can you please provide me with your order number and email address?\n",
    "Customer: Yes, my order number is 123456789 and my email is john.doe@example.com.\n",
    "AI agent: Thank you. I have found your order in our system. It looks like your order is still being processed and it will be shipped soon. You should receive a confirmation email within 24 hours.\n",
    "Customer: OK, thank you for the information. How long will it take for the shoes to arrive?\n",
    "AI agent: You're welcome. According to our shipping policy, it will take about 3 to 5 business days for the shoes to arrive at your address. You can track your order online using the tracking number that will be sent to your email once your order is shipped.\n",
    "Customer: Alright, sounds good. Thank you for your help.\n",
    "AI agent: It's my pleasure. Is there anything else I can do for you today?\n",
    "Customer: No, that's all. Have a nice day.\n",
    "AI agent: Thank you for choosing our online store. Have a nice day too. Goodbye. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": conversation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are a sentiment analyzer. You classify conversations into three categories: positive, negative or neutral.\n",
    "Return only the sentiment, in lower cap and without punctuation.\n",
    "\n",
    "Conversation:\n",
    "{conversation}\n",
    "\n",
    "Remember to return only the sentiment, in lower cap and without punctuation!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A neutron is a subatomic particle that has a neutral (not positive or negative) charge, and a mass slightly greater than that of a proton. \n",
    "It is present in all atomic nuclei except those of ordinary hydrogen. \n",
    "Neutrons, along with protons and electrons, are one of the three basic particles making up atoms. \n",
    "The term “neutron” comes from the fact that it is electrically neutral, meaning it carries no charge.\n",
    "\"\"\"\n",
    "\n",
    "system_message = f\"\"\"\n",
    "Reframe the text for a 5 years old child. It should be shorter than 500 words. Make a parallelism with animals.\n",
    "\n",
    "The text is the following:\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a Python expert that produces python code as per user's request.\n",
    "\n",
    "===>START EXAMPLE\n",
    "\n",
    "---User Query---\n",
    "Give me a function to print a string of text.\n",
    "\n",
    "---User Output---\n",
    "Below you can find the described function:\n",
    "```def my_print(text):\n",
    "     return print(text)\n",
    "```\n",
    "<===END EXAMPLE\n",
    "\"\"\"\n",
    "\n",
    "query = \"generate a python function to calculate the nth Fibonacci number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
    "Given a product name, produce a tagline similar to the following examples:\n",
    "\n",
    "Peak Pursuit - Conquer Heights with Comfort\n",
    "Summit Steps - Your Partner for Every Ascent\n",
    "Crag Conquerors - Step Up, Stand Tal\n",
    "\n",
    "Product name:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "product_name = 'Elevation Embrace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": product_name},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd .read_csv('movie.csv', encoding='utf-8')\n",
    "df['label'] = df['label'].replace({0: 'Negative', 1: 'Positive'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=10, random_state=42)  # Change the value of 'random_state' as needed for reproducibility\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a binary classifier for sentiment analysis.\n",
    "Given a text, based on its sentiment you classify it into one of two categories: positive or negative.\n",
    "\n",
    "You can use the following texts as examples:\n",
    "\n",
    "Text: \"I love this product! It's fantastic and works perfectly.\"\n",
    "Positive\n",
    "\n",
    "Text: \"I'm really disappointed with the quality of the food.\"\n",
    "Negative\n",
    "\n",
    "Text: \"This is the best day of my life!\"\n",
    "Positive\n",
    "\n",
    "Text: \"I can't stand the noise in this restaurant.\"\n",
    "Negative\n",
    "\n",
    "ONLY return the sentiment as output (without punctuation).\n",
    "\n",
    "Text:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text = \"The concert was amazing! The band was incredible!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "df['predicted'] = df['text'].apply(process_text)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "To solve a generic first-degree equation, follow these steps:\n",
    "\n",
    "1. **Identify the Equation:** Start by identifying the equation you want to solve. It should be in the form of \"ax + b = c,\" where 'a' is the coefficient of the variable, 'x' is the variable, 'b' is a constant, and 'c' is another constant.\n",
    "\n",
    "2. **Isolate the Variable:** Your goal is to isolate the variable 'x' on one side of the equation. To do this, perform the following steps:\n",
    "   \n",
    "   a. **Add or Subtract Constants:** Add or subtract 'b' from both sides of the equation to move constants to one side.\n",
    "   \n",
    "   b. **Divide by the Coefficient:** Divide both sides by 'a' to isolate 'x'. If 'a' is zero, the equation may not have a unique solution.\n",
    "\n",
    "3. **Simplify:** Simplify both sides of the equation as much as possible.\n",
    "\n",
    "4. **Solve for 'x':** Once 'x' is isolated on one side, you have the solution. It will be in the form of 'x = value.'\n",
    "\n",
    "5. **Check Your Solution:** Plug the found value of 'x' back into the original equation to ensure it satisfies the equation. If it does, you've found the correct solution.\n",
    "\n",
    "6. **Express the Solution:** Write down the solution in a clear and concise form.\n",
    "\n",
    "7. **Consider Special Cases:** Be aware of special cases where there may be no solution or infinitely many solutions, especially if 'a' equals zero.\n",
    "\n",
    "\n",
    "Equation:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "equation = \"3x + 5 = 11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": equation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://bookcodetest.openai.azure.com/openai\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"***REMOVED***\"\n",
    "\n",
    "# Modified endpoint without /openai\n",
    "os.environ[\"AZURE_ENDPOINT\"] = \"https://bookcodetest.openai.azure.com\"\n",
    "os.environ[\"AZURE_DEPLOYMENT\"] = \"gpt-4o\"\n",
    "os.environ[\"AZURE_API_KEY\"] = \"***REMOVED***\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"2024-08-01-preview\"\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"***REMOVED***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict, Union\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import operator\n",
    "from langchain.tools import Tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Initialize the model\n",
    "model = AzureChatOpenAI(\n",
    "    deployment_name='gpt-4o',\n",
    "    azure_deployment=os.getenv('AZURE_DEPLOYMENT'),\n",
    "    azure_endpoint=os.getenv('AZURE_ENDPOINT'),\n",
    "    api_key=os.getenv('AZURE_API_KEY'),\n",
    "    api_version=os.getenv('AZURE_API_VERSION')\n",
    ")\n",
    "\n",
    "# Set up tools\n",
    "search = SerpAPIWrapper(serpapi_api_key=os.environ[\"SERPAPI_API_KEY\"])\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define the agent state\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "# Create the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant. When you need information about current events, use the Search tool. To use the tool, respond with: TOOL: Search QUERY: your search query\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "# Define the agent function\n",
    "def agent_func(state: AgentState) -> Union[AgentState, str]:\n",
    "    # Prepare messages for the model\n",
    "    messages = prompt.format_messages(\n",
    "        messages=state[\"messages\"],\n",
    "        tool_names=\"Search\"\n",
    "    )\n",
    "    \n",
    "    # Generate model response\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Check if response indicates tool usage\n",
    "    if \"TOOL: Search\" in response.content:\n",
    "        # Extract query after \"QUERY:\"\n",
    "        query = response.content.split(\"QUERY:\")[1].strip()\n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Searching for: {query}\")],\n",
    "            \"next\": \"search_tool\",\n",
    "            \"tool_input\": query\n",
    "        }\n",
    "    \n",
    "    # If no tool is needed, end the conversation\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"next\": END\n",
    "    }\n",
    "\n",
    "# Create search tool node\n",
    "search_tool = ToolNode(tools)\n",
    "\n",
    "# Create the workflow\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_func)\n",
    "workflow.add_node(\"search_tool\", search_tool)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"agent\", \"search_tool\")\n",
    "workflow.add_edge(\"search_tool\", \"agent\")\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "chain = workflow.compile()\n",
    "\n",
    "# Function to invoke the agent\n",
    "def invoke_agent(message: str):\n",
    "    result = chain.invoke({\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"next\": \"agent\"\n",
    "    })\n",
    "    # Return all messages for better context\n",
    "    return \"\\n\".join([msg.content for msg in result[\"messages\"]])\n",
    "\n",
    "# Example usage\n",
    "response = invoke_agent('who are going to be the italian male athletes for climbing at the Paris 2024 Olympics?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
